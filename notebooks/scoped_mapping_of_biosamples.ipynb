{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac2962f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pkg_resources import get_distribution, DistributionNotFound\n",
    "from strsimpy.cosine import Cosine\n",
    "import pandas as pd\n",
    "import re\n",
    "import requests as requests\n",
    "import sqlite3\n",
    "import string\n",
    "import urllib\n",
    "import yaml\n",
    "from xml.etree import ElementTree\n",
    "from tdda import rexpy\n",
    "import scoped_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5684af0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "biosample_sqlite_file = \"/Users/MAM/Documents/gitrepos/biosample-analysis/target/harmonized_table.db\"\n",
    "# TODO process these as a list?\n",
    "ncbitaxon_sqlite_file = \"/Users/MAM/Documents/gitrepos/semantic-sql/db/ncbitaxon.db\"\n",
    "envo_sqlite_file = \"/Users/MAM/Documents/gitrepos/semantic-sql/db/envo.db\"\n",
    "ncbitaxon_cnx = sqlite3.connect(ncbitaxon_sqlite_file)\n",
    "envo_cnx = sqlite3.connect(envo_sqlite_file)\n",
    "target_onto_prefix = 'ENVO'\n",
    "chars_to_whiteout = '._-'\n",
    "my_query_fields = ''\n",
    "my_row_req = 3\n",
    "\n",
    "env_package_overrides = {\n",
    "    'built environment': 'built',\n",
    "    'misc environment': 'miscellaneous',\n",
    "    'missing': 'no environmental package',\n",
    "    'unknown': 'no environmental package',\n",
    "    'default': 'no environmental package',\n",
    "    'unspecified': 'no environmental package',\n",
    "    'not available': 'no environmental package',\n",
    "    'not collected': 'no environmental package'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9282126f",
   "metadata": {},
   "outputs": [],
   "source": [
    "biosample_cnx = sqlite3.connect(biosample_sqlite_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caff574e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample of the data we're working with\n",
    "q = \"\"\"\n",
    "select\n",
    "    id,\n",
    "    env_package,\n",
    "    package,\n",
    "    package_name,\n",
    "    host_taxid,\n",
    "    taxonomy_id,\n",
    "    env_broad_scale,\n",
    "    env_local_scale,\n",
    "    env_medium\n",
    "    from biosample b\n",
    "limit 10\n",
    "\"\"\"\n",
    "biosample_first_ten = pd.read_sql(q, biosample_cnx)\n",
    "biosample_first_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cc9596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the canonical checklist and package terms from NCBI\n",
    "# Unfortunately it doesn't do a very good job of differentiating \n",
    "# checklists (MIMAG, MIMARKS, etc.) \n",
    "# from packages (soil, water, etc.)\n",
    "# what about ba , euk, etc?\n",
    "package_dictionary = scoped_mapping.get_package_dictionary()\n",
    "package_dictionary.to_sql('package_dictionary', biosample_cnx, if_exists='replace', index=False)\n",
    "package_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfa7d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the Biosample checklist/package fields match any of the cannonical values?\n",
    "# How many Biosample rows are there?\n",
    "q = \"\"\"\n",
    "select count(*) as biosample_row_count\n",
    "from biosample b\n",
    "\"\"\"\n",
    "[biosample_row_count, query_duration] = scoped_mapping.timed_query(q, biosample_cnx, print_timing=False)\n",
    "\n",
    "print(query_duration)\n",
    "biosample_row_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a8b90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many of those rows can be inner-joined with the canonical checklists/packages?\n",
    "# Specifically, joining biosample.package_name = package_dictionary.DisplayName\n",
    "# TODO add indexing to docs and or makefile\n",
    "# create index biosample_package_name_idx on biosample(package_name);\n",
    "# create index package_dictionary_DisplayName_idx on package_dictionary(DisplayName);\n",
    "# create index biosample_package_idx on biosample(package);\n",
    "# create index biosample_p_pn_idx on biosample(package, package_name);\n",
    "q = \"\"\"\n",
    "select\n",
    "    count(*) as cannonical_package_name_count\n",
    "from\n",
    "    biosample b\n",
    "inner join package_dictionary pd on\n",
    "    b.package_name = pd.DisplayName\n",
    "\"\"\"\n",
    "[cannonical_package_name_count, query_duration] = scoped_mapping.timed_query(q, biosample_cnx, print_timing=True)\n",
    "\n",
    "print(query_duration)\n",
    "\n",
    "cannonical_package_name_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83485b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What do the combinations of package and package_name look like in the Biosample dataset?\n",
    "q = \"\"\"\n",
    "select\n",
    "    package,\n",
    "    package_name,\n",
    "    count(*) as count\n",
    "from\n",
    "    biosample b\n",
    "group by\n",
    "    package ,\n",
    "    package_name\n",
    "order by\n",
    "    package ,\n",
    "    package_name\n",
    "\"\"\"\n",
    "[package_name_combos, query_duration] = scoped_mapping.timed_query(q, biosample_cnx, print_timing=True)\n",
    "\n",
    "print(query_duration)\n",
    "\n",
    "package_name_combos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d042df82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What about the Biosample env_package values?\n",
    "# Are they also a small, highly regular set?\n",
    "q = \"\"\"\n",
    "select\n",
    "    env_package,\n",
    "    count(*) as count\n",
    "from\n",
    "    biosample b\n",
    "group by\n",
    "    env_package\n",
    "order by\n",
    "    count(*) desc\n",
    "\"\"\"\n",
    "[env_package_count, query_duration] = scoped_mapping.timed_query(q, biosample_cnx)\n",
    "\n",
    "print(query_duration)\n",
    "\n",
    "env_package_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ba2408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# env_package is going to need some cleanup\n",
    "# First, get a set of all canonical env_package values\n",
    "package_dictionary = scoped_mapping.make_tidy_col(package_dictionary, 'EnvPackage', 'eptidy')\n",
    "package_dictionary =scoped_mapping.make_tidy_col(package_dictionary, 'EnvPackageDisplay', 'epdtidy')\n",
    "# update in sqlite\n",
    "package_dictionary.to_sql('package_dictionary', biosample_cnx, if_exists='replace', index=False)\n",
    "valid_combo = []\n",
    "valid_combo = scoped_mapping.add_unique_to_list(valid_combo, package_dictionary['eptidy'])\n",
    "valid_combo = scoped_mapping.add_unique_to_list(valid_combo, package_dictionary['epdtidy'])\n",
    "\n",
    "valid_combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d157f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine ID patterns\n",
    "q = \"\"\"\n",
    "select\n",
    "    distinct stanza\n",
    "    from statements s\n",
    "where\n",
    "    predicate = 'rdf:type'\n",
    "    and \"object\" = 'owl:Class'\n",
    "    and stanza = subject\"\"\"\n",
    "# include non-envo IDs that come from envo?\n",
    "[ids_from_envo, query_duration] = scoped_mapping.timed_query(q, envo_cnx)\n",
    "print(query_duration)\n",
    "ids_from_envo = scoped_mapping.add_prefix_col(ids_from_envo, 'stanza', 'prefix')\n",
    "\n",
    "id_patterns = scoped_mapping.get_multi_term_patterns(ids_from_envo, 'stanza', 'prefix')\n",
    "\n",
    "env_package_normalized = scoped_mapping.env_package_nomralizastion(env_package_count, 'env_package',\n",
    "                                                                target_onto_prefix, id_patterns['ENVO'])\n",
    "\n",
    "env_package_normalized = scoped_mapping.add_overrides(env_package_normalized, 'remaining_tidied', 'ep_override',\n",
    "                                                   env_package_overrides)\n",
    "\n",
    "env_package_normalized = scoped_mapping.flag_canonical(env_package_normalized, 'ep_override', 'is_canonical',\n",
    "                                                    valid_combo)\n",
    "\n",
    "env_package_normalized.to_sql('env_package_normalized', biosample_cnx, if_exists='replace', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1fbb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What do the successful normalizations look like?\n",
    "q = \"\"\"\n",
    "select\n",
    "    env_package,\n",
    "    count,\n",
    "    lhs,\n",
    "    extract,\n",
    "    ep_override\n",
    "from\n",
    "    env_package_normalized\n",
    "where\n",
    "    is_canonical = 1\n",
    "\"\"\"\n",
    "[successful_normalizastions, query_duration] = scoped_mapping.timed_query(q, biosample_cnx)\n",
    "\n",
    "print(query_duration)\n",
    "\n",
    "successful_normalizastions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e08383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are there any normalization failures?\n",
    "q = \"\"\"\n",
    "select\n",
    "    env_package,\n",
    "    count,\n",
    "    lhs,\n",
    "    extract,\n",
    "    ep_override\n",
    "from\n",
    "    env_package_normalized\n",
    "where\n",
    "    is_canonical = 0\n",
    "\"\"\"\n",
    "[normalizastion_failures, query_duration] = scoped_mapping.timed_query(q, biosample_cnx)\n",
    "\n",
    "print(query_duration)\n",
    "\n",
    "normalizastion_failures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40903d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilizing ncbtitaxon for broad subsetting\n",
    "# specifically, flag the biosamples whose taxon_id indicates they are an unclassified entity\n",
    "# ignoring the others will throw out samples OF multicellular organisms, like fruit flies\n",
    "# Add previous notes about what kinds of samples are missed by this bifurcation\n",
    "# like bacteria.unclassified_bacteria\n",
    "\n",
    "q = \"\"\"\n",
    "select\n",
    "    distinct s.subject\n",
    "from\n",
    "    entailed_edge ee\n",
    "join statements s on\n",
    "    ee.subject = s.subject\n",
    "where\n",
    "    ee.predicate = 'rdfs:subClassOf'\n",
    "    and ee.object = 'NCBITaxon:2787823'\n",
    "    and s.predicate = 'rdfs:label'\n",
    "\"\"\"\n",
    "[unclassified_taxa, query_duration] = scoped_mapping.timed_query(q, ncbitaxon_cnx)\n",
    "unclassified_taxa['unclassified'] = True\n",
    "\n",
    "print(query_duration)\n",
    "\n",
    "unclassified_taxa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d8f028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SLOW... CHECK INDICES\n",
    "# Get the taxonomy_id values from the Biosamples\n",
    "q = \"\"\"\n",
    "select\n",
    "    taxonomy_id biosample_taxid,\n",
    "    count(*) as count\n",
    "from\n",
    "    biosample b\n",
    "group by\n",
    "    taxonomy_id\n",
    "order by\n",
    "    count(*) desc\n",
    "\"\"\"\n",
    "[biosample_tax_id_counts, query_duration] = scoped_mapping.timed_query(q, biosample_cnx)\n",
    "biosample_tax_id_counts['curie'] = 'NCBITaxon:' + biosample_tax_id_counts['biosample_taxid'].astype(str)\n",
    "\n",
    "print(query_duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ad29a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two taxon id datasets\n",
    "# I.e. flag the the Biosample records whose taxonomy_id field belongs to a subclass of 'unclassified entries'.\n",
    "biosample_tax_id_counts = biosample_tax_id_counts.merge(unclassified_taxa, left_on='curie',\n",
    "                                                        right_on='subject', how='left')\n",
    "biosample_tax_id_counts.unclassified.fillna(False, inplace=True)\n",
    "\n",
    "biosample_tax_id_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6acc349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# should really add labels to all of them\n",
    "q = \"\"\"\n",
    "select\n",
    "    subject ,\n",
    "    value\n",
    "from statements\n",
    "where\n",
    "    predicate = 'rdfs:label' and subject = stanza\n",
    "\"\"\"\n",
    "[all_tax_labels, query_duration] = scoped_mapping.timed_query(q, ncbitaxon_cnx)\n",
    "\n",
    "biosample_tax_id_counts = biosample_tax_id_counts.merge(all_tax_labels, left_on='curie',\n",
    "                                                        right_on='subject', how='left')\n",
    "\n",
    "biosample_tax_id_counts = biosample_tax_id_counts[['curie', 'biosample_taxid', 'count', 'unclassified', 'value']]\n",
    "biosample_tax_id_counts.columns = ['curie', 'biosample_taxid', 'count', 'unclassified', 'label']\n",
    "\n",
    "print(query_duration)\n",
    "biosample_tax_id_counts.to_sql('biobiosample_tax_id_counts', biosample_cnx, if_exists='replace', index=False)\n",
    "\n",
    "biosample_tax_id_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554a82c0",
   "metadata": {},
   "source": [
    "Almost all of the taxa that are common in the biosample collection are either unclassified/metagenomes or easily recognized cellular organisms\n",
    "\n",
    "exceptions include:\n",
    "- 32630 = synthetic construct (other entries; other sequences; artificial sequences)\n",
    "    - 'other entries' would add 16k rows on top of the 1k 'unclassified entities'\n",
    "    - metagenomes account for 331 of the 'unclassified entities'\n",
    "    - there are also a small number of uncultured/unclassified microorganisms in the biosample dataset\n",
    "- 77133 = uncultured bacterium (cellular organisms; Bacteria; environmental samples)\n",
    "    - 'cellular organisms' would add 2M rows on top of the 1k 'unclassified entities'\n",
    "    - 'cellular organisms; Bacteria; environmental samples' adds 26k\n",
    "    \n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e777c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a table of scoped mixs annotations to be mapped to ontology classes.\n",
    "biosample_col_to_map = 'env_broad_scale'\n",
    "scoping_col = 'env_package_normalized.ep_override'\n",
    "scoping_value = 'water'\n",
    "# In this case, the scoping includes an inner join requirement for 'unclassified entities'\n",
    "\n",
    "q = 'select ' + biosample_col_to_map + \"\"\", count(*) as count\n",
    "from\n",
    "    biosample b\n",
    "join env_package_normalized on\n",
    "    b.env_package = env_package_normalized.env_package\n",
    "inner join biobiosample_tax_id_counts stic on\n",
    "    b.taxonomy_id = stic.biosample_taxid\n",
    "where \"\"\" + scoping_col + \" = '\" + scoping_value + \\\n",
    "    \"' group by \" + biosample_col_to_map + \"\"\"\n",
    "order by\n",
    "    count(*) desc\"\"\"\n",
    "[mapping_candidates, query_duration] = scoped_mapping.timed_query(q, biosample_cnx)\n",
    "\n",
    "mapping_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e1859f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Biosample format allows for pipe-delimited environmental package lists\n",
    "# Separate those out into their components\n",
    "multi_frames = []\n",
    "for row in mapping_candidates.itertuples(index=True, name='Pandas'):\n",
    "    split_check = row.env_broad_scale\n",
    "    if split_check is None:\n",
    "        split_check = ''\n",
    "    splitted = pd.Series(split_check.split(\"|\"))\n",
    "    splitted_count = len(splitted)\n",
    "    repeated = [split_check] * splitted_count\n",
    "    repeated = pd.Series(repeated)\n",
    "    as_frame = pd.DataFrame(dict(repeated=repeated, splitted=splitted)).reset_index()\n",
    "    multi_frames.append(as_frame)\n",
    "concat_frame = pd.concat(multi_frames)\n",
    "concat_frame = concat_frame[['repeated', 'splitted']]\n",
    "mapping_candidates = mapping_candidates.merge(concat_frame, left_on=biosample_col_to_map,\n",
    "                                              right_on='repeated', how='left')\n",
    "\n",
    "mapping_candidates\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e423fcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the spliting and extraction here\n",
    "\n",
    "# Now try to extract ontology terms that are already present\n",
    "candidate_series_decomposition = scoped_mapping.decompose_series(mapping_candidates['splitted'], id_patterns[target_onto_prefix])\n",
    "mapping_candidates = pd.concat([mapping_candidates, candidate_series_decomposition], axis=1)\n",
    "\n",
    "mapping_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448865ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And join the extracted IDs with their labels\n",
    "# start by conencting to the rdftab database \n",
    "# from which the terms and label-like annotatiosn will be obtained\n",
    "ontodb = '/Users/MAM/Documents/gitrepos/semantic-sql/db/' + target_onto_prefix.lower() + '.db'\n",
    "ontocon = sqlite3.connect(ontodb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcd7e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "select\n",
    "    subject ,\n",
    "    value\n",
    "from\n",
    "    statements s\n",
    "where\n",
    "    predicate = 'rdfs:label'\n",
    "\"\"\"\n",
    "[onto_labels, query_duration] = scoped_mapping.timed_query(q, ontocon)\n",
    "\n",
    "onto_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8543ed0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_candidates = mapping_candidates.merge(onto_labels, left_on='extract', right_on='subject', how='left')\n",
    "mapping_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e25da0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd0a035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use cosine string distance to see if the labels match\n",
    "# I.e. the labels claimed by the Biosample data set and the labels asserted in the ontology\n",
    "# if they're close enough, consider the assigned ID legit\n",
    "# how close is close enough?\n",
    "my_cosine_obj = Cosine(1)\n",
    "mapping_candidates['value'] = mapping_candidates['value'].fillna('')\n",
    "mapping_candidates['cosine'] = mapping_candidates.apply(\n",
    "    lambda my_row: my_cosine_obj.distance(my_row['remaining_tidied'].lower(), my_row['value'].lower()), axis=1)\n",
    "mapping_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092aced0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get ready to join in the other direction\n",
    "# I.e. trying to find ontology term IDs based on perfect label matches. Be careful not to reuse column names.\n",
    "mapping_candidates.columns = ['env_broad_scale', 'count', 'repeated', 'splitted', 'string', 'extract',\n",
    "                              'remaining_string', 'remaining_tidied', 'term_id', 'lab_from_id', 'lfi_cosine']\n",
    "mapping_candidates = mapping_candidates.merge(onto_labels, left_on='remaining_tidied', right_on='value', how='left')\n",
    "mapping_candidates.columns = ['env_broad_scale', 'count', 'repeated', 'splitted', 'string', 'extract',\n",
    "                              'remaining_string', 'remaining_tidied', 'term_id', 'lab_from_id',\n",
    "                              'lfi_cosine', 'term_id_from_lab', 'value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0d4f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5e3fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record a consensus\n",
    "# If either merging on codes or labels was successful.\n",
    "# cosines for first pass check on assigned IDs still haven't been filtered?\n",
    "mapping_candidates['consensus_id'] = mapping_candidates['term_id']\n",
    "mapping_candidates['consensus_id'][mapping_candidates['consensus_id'].isnull()] = \\\n",
    "    mapping_candidates['term_id_from_lab'][mapping_candidates['consensus_id'].isnull()]\n",
    "mapping_candidates['consensus_lab'] = mapping_candidates['lab_from_id']\n",
    "mapping_candidates['consensus_lab'][mapping_candidates['consensus_lab'] == ''] = \\\n",
    "    mapping_candidates['value'][mapping_candidates['consensus_lab'] == '']\n",
    "# mapping_candidates.to_sql('mapping_scratch', biosample_cnx, if_exists='replace', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c7644d",
   "metadata": {},
   "source": [
    "```\n",
    "<ipython-input-49-3e62557cf6d9>:5: SettingWithCopyWarning: \n",
    "A value is trying to be set on a copy of a slice from a DataFrame\n",
    "\n",
    "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
    "  mapping_candidates['consensus_id'][mapping_candidates['consensus_id'].isnull()] = \\\n",
    "<ipython-input-49-3e62557cf6d9>:8: SettingWithCopyWarning: \n",
    "A value is trying to be set on a copy of a slice from a DataFrame\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af120f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29338b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For which Biosample annotations were not mappings by merging found?\n",
    "# It looks like remaining_tidied is retaining too much punctuation\n",
    "# and loosing useful digits (relative to remaining_string)?\n",
    "# Should try harder to parse not-quite-right embedded IDs like ...\n",
    "needs_search = mapping_candidates.remaining_tidied[mapping_candidates.consensus_id.isna()]\n",
    "needs_search_counts = needs_search.value_counts()\n",
    "\n",
    "needs_search_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a43f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a search engine\n",
    "# For the mixs annotations that didn't already have cannonical IDs or labels\n",
    "ebs_raw_list = list(needs_search_counts.index)\n",
    "ebs_raw_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c944a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get whiteout frame and relateds\n",
    "ebs_wo_frame = scoped_mapping.get_whiteout_frame(ebs_raw_list, replaced_chars=chars_to_whiteout)\n",
    "\n",
    "ebs_wo_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c0f419",
   "metadata": {},
   "outputs": [],
   "source": [
    "ebs_wo_list = scoped_mapping.get_wo_list(ebs_wo_frame)\n",
    "ebs_wo_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e39629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slow... turn logging back on to show status?\n",
    "ebs_search_res = scoped_mapping.search_get_annotations_wrapper(ebs_wo_list, bad_chars=chars_to_whiteout, cat_name=biosample_col_to_map,\n",
    "                                                ontoprefix=target_onto_prefix.lower(), query_fields='', rr=5)\n",
    "my_best_acceptable = scoped_mapping.get_best_acceptable(ebs_search_res)\n",
    "\n",
    "my_best_acceptable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e98bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_acceptable_mappings = scoped_mapping.get_no_acceptable_mappings(ebs_search_res, my_best_acceptable)\n",
    "\n",
    "no_acceptable_mappings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07cdab1",
   "metadata": {},
   "source": [
    "- Some broad scales look like place names\n",
    "- Some get a good hit if 'biome' is added\n",
    "- how to manually review and then add back in?\n",
    "- add to biosample SQLite database:\n",
    "    - no_acceptable_mappings\n",
    "    - my_best_acceptable\n",
    "    - ebs_search_results (no acceptable + all acceptable)?\n",
    "    - mapping_candidates -> mapping_scratch (ID-based and exact-tidied-label-based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6219e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
